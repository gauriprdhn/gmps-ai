{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c774bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym import spaces\n",
    "from dataprep.dataset import load_reformated_csv, create_dataset\n",
    "import json\n",
    "import keras\n",
    "from globals import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0fb4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(df ,\n",
    "                variable: str = 'B:VIMIN' ,\n",
    "                train_test_split: float = 0.7) :\n",
    "    dataset = df[variable].values\n",
    "    dataset = dataset.astype( 'float32' )\n",
    "    dataset = np.reshape( dataset , (-1 , 1) )\n",
    "\n",
    "    train_size = int( len( dataset ) * train_test_split )\n",
    "    train , test = dataset[0 :train_size , :] , dataset[train_size :len( dataset ) , :]\n",
    "\n",
    "    X_train , Y_train = create_dataset( train , look_back = LOOK_BACK )\n",
    "    X_train = np.reshape ( X_train , (X_train.shape [ 0 ] , X_train.shape [ 1 ], 1) )\n",
    "    Y_train = np.reshape ( Y_train , (Y_train.shape [ 0 ] , Y_train.shape [ 1 ]) )\n",
    "\n",
    "    return X_train , Y_train\n",
    "\n",
    "def all_inplace_scale(df) :\n",
    "    scale_dict = {}\n",
    "\n",
    "    for var in VARIABLES :\n",
    "        our_data2 = df\n",
    "        trace = our_data2[var].astype( 'float32' )\n",
    "        data = np.array( trace )\n",
    "\n",
    "        median = np.median( data )\n",
    "        upper_quartile = np.percentile( data , 75 )\n",
    "        lower_quartile = np.percentile( data , 25 )\n",
    "\n",
    "        iqr = upper_quartile - lower_quartile\n",
    "        lower_whisker = data[data >= lower_quartile - 1.5 * iqr].min( )\n",
    "        upper_whisker = data[data <= upper_quartile + 1.5 * iqr].max( )\n",
    "\n",
    "        ranged = upper_whisker - lower_whisker\n",
    "        # (value âˆ’ median) / (upper - lower)\n",
    "        our_data2[var] = 1 / ranged * (data - median)\n",
    "\n",
    "        scale_dict[str( var )] = {\"median\" : median , \"range\" : ranged}\n",
    "\n",
    "    return scale_dict\n",
    "\n",
    "def unscale(var_name , tseries , scale_dict) :\n",
    "    # equivalent to inverse transform\n",
    "    from_model = np.asarray( tseries )\n",
    "    update = from_model * scale_dict[str( var_name )][\"range\"] + scale_dict[str( var_name )][\"median\"]\n",
    "\n",
    "    return (update)\n",
    "\n",
    "def rescale(var_name , tseries , scale_dict) :\n",
    "    # equivalent to transform\n",
    "    data = np.asarray( tseries )\n",
    "    update = 1 / scale_dict[str( var_name )][\"range\"] * (data - scale_dict[str( var_name )][\"median\"])\n",
    "\n",
    "    return (update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed7ee223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dropout_predict_model(model , dropout) :\n",
    "    # Load the config of the original model\n",
    "    conf = model.get_config( )\n",
    "\n",
    "    # Add the specified dropout to all layers\n",
    "    for layer in conf['layers'] :\n",
    "        if layer[\"class_name\"] == \"Dropout\" :\n",
    "            # print(layer)\n",
    "            layer[\"config\"][\"rate\"] = dropout\n",
    "    model_dropout = keras.Model.from_config( conf )\n",
    "    model_dropout.set_weights( model.get_weights( ) )\n",
    "    return model_dropout\n",
    "\n",
    "\n",
    "def regulation(alpha , gamma , error , min_set , beta) :\n",
    "    ## calculate the prediction with current regulation rules\n",
    "    ## from Rachael's report, eq (1)\n",
    "    # beta=[0]\n",
    "    ER = error  # error\n",
    "    _MIN = min_set  # setting\n",
    "    for i in range( len( _MIN ) ) :\n",
    "        if i > 0 :\n",
    "            beta_t = beta[-1] + gamma * ER[i]\n",
    "            beta.append( beta_t )  # hopefully this will update self.rachael_beta in place\n",
    "\n",
    "    MIN_pred = _MIN - alpha * ER - np.asarray( beta[-LOOK_BACK :] ).reshape( LOOK_BACK ,\n",
    "                                                                             1 )  # predict the next, shiftting happens in the plotting #check here\n",
    "    return MIN_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd23bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    filepath = LATEST_SURROGATE_MODEL ,\n",
    "    compile = False )\n",
    "booster_model = create_dropout_predict_model( model , .2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eab98747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from config\n",
    "with open( DATA_CONFIG ) as json_file :\n",
    "    data_config = json.load( json_file )\n",
    "data = load_reformated_csv( filename = data_config['data_dir'] + data_config['data_filename'] ,\n",
    "                            nrows = NSTEPS )\n",
    "scale_dict = all_inplace_scale( data )\n",
    "data['B:VIMIN'] = data['B:VIMIN'].shift( -1 )\n",
    "data = data.set_index( pd.to_datetime( data.time ) )\n",
    "data = data.dropna( )\n",
    "data = data.drop_duplicates( )\n",
    "variables = VARIABLES\n",
    "nvariables = len( variables )\n",
    "\n",
    "data_list = []\n",
    "x_train = []\n",
    "# get_dataset also normalizes the data\n",
    "for v in range( len( variables ) ) :\n",
    "    data_list.append( get_dataset( data , variable = variables[v] ) )\n",
    "    # self.scalers.append(data_list[v][0])\n",
    "    x_train.append( data_list[v][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82efad92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:(174982, 15, 6)\n"
     ]
    }
   ],
   "source": [
    "concate_axis = 2\n",
    "X_train = np.concatenate(x_train, axis=concate_axis)\n",
    "print( 'Data shape:{}'.format( X_train.shape ) )\n",
    "nbatches = X_train.shape[0]\n",
    "nsamples = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c51053b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.zeros(shape=(1, 15, 6))\n",
    "predicted_state = np.zeros(shape = (1, 6, 1))\n",
    "rachael_state = np.zeros(shape=(1, 15, 6))\n",
    "rachael_predicted_state = np.zeros(shape = (1, 6, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ee0674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "observation_space = spaces.Box(\n",
    "    low = 0 ,\n",
    "    high = +1 ,\n",
    "    shape = (6 ,) ,\n",
    "    dtype = np.float64\n",
    "    )\n",
    "actionMap_VIMIN = [0 , 0.0001 , 0.005 , 0.001 , -0.0001 , -0.005 , -0.001]\n",
    "action_space = spaces.Discrete( 7 )\n",
    "VIMIN = 0\n",
    "action = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8cb5df8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103.39762797]]\n"
     ]
    }
   ],
   "source": [
    "delta_VIMIN = actionMap_VIMIN[action]\n",
    "DENORN_BVIMIN = unscale( variables[0] , np.array( [VIMIN] ).reshape( 1 , -1 ) ,\n",
    "                                 scale_dict )\n",
    "DENORN_BVIMIN += delta_VIMIN\n",
    "print(DENORN_BVIMIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e3b7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 10e-2\n",
    "gamma = 7.535e-5\n",
    "rachael_beta = [0]\n",
    "B_VIMIN_trace = unscale( variables[2] , state[0 , : , 2].reshape( -1 , 1 ) ,\n",
    "                         scale_dict )\n",
    "BIMINER_trace = unscale( variables[1] , state[0 , : , 1].reshape( -1 , 1 ) ,\n",
    "                         scale_dict )\n",
    "\n",
    "rachael_state[0][nsamples - 1][0] = rescale( variables[0] ,\n",
    "                                           regulation( alpha , gamma ,\n",
    "                                                       error = BIMINER_trace ,\n",
    "                                                       min_set = B_VIMIN_trace ,\n",
    "                                                       beta = rachael_beta )[\n",
    "                                               -1].reshape( -1 , 1 ) ,\n",
    "                                           scale_dict ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2617f0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.00085206,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VIMIN = rescale( variables[0] , DENORN_BVIMIN ,\n",
    "                  scale_dict ) \n",
    "state[0][nsamples - 1][0] = VIMIN\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bdb0afe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.8397697],\n",
       "        [-1.567316 ]]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_state = booster_model.predict( state ).reshape(1, 2, 1)\n",
    "predicted_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a98d5022",
   "metadata": {},
   "outputs": [],
   "source": [
    "state[0 , 0 :-1, :] = state[0, 1 :, :]  # shift forward\n",
    "rachael_state[0 , 0 :-1, : ] = rachael_state[0 , 1 :, : ]\n",
    "\n",
    "# Update IMINER\n",
    "state[0][nsamples - 1][1] = predicted_state[0 , 1 :2]\n",
    "rachael_state[0][nsamples - 1][1] = rachael_predicted_state[0 , 1 :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a606952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0746875]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_state = None\n",
    "data_state = np.copy(\n",
    "    X_train[1000 + 1].reshape( 1 , 15, 6 ) )\n",
    "data_iminer = unscale( variables[1] ,\n",
    "                       data_state[0][nsamples - 1][1].reshape( 1 , -1 ) ,\n",
    "                       scale_dict )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e0064d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state[0 , :, 2 :6] = data_state[0 , :, 2 :6]\n",
    "rachael_state[0 , :, 2:6] = data_state[0 , :, 2 :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d44aacdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[0, -1 :, :].flatten( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1bda7c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = np.random.randint( low = 500 , high = 5000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c8fea29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = np.copy(X_train[batch_id].reshape(1, 15, 6))\n",
    "state[0 , -1:, :].flatten( ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717363b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
